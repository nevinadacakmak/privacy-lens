# PrivacyLens üîç

_A framework to evaluate memorization and privacy risks in large language models._

## Overview

PrivacyLens explores how large language models (LLMs) memorize sensitive data and how differential privacy techniques can reduce these risks.  
We focus on:

- Measuring memorization with **canary insertion tests** and **membership inference**.
- Applying **differentially private stochastic gradient descent (DP-SGD)** using [Opacus](https://opacus.ai/).
- Reporting trade-offs between model utility (accuracy, perplexity) and privacy guarantees (leakage reduction, Œµ).

## Repository Structure

- `notebooks/` ‚Äì Reproducible experiments and analysis.
- `scripts/` ‚Äì Modular training and evaluation code.
- `data/` ‚Äì Scripts or links for dataset preparation.
- `results/` ‚Äì Experiment logs and plots.

## Quick Start

1. Clone this repo:
   ```bash
   git clone https://github.com/nevinadacakmak/privacy-lens.git
   cd privacylens
   ```

## to do

add gpt-2

---

# PrivacyLens üîç

PrivacyLens is a prototype framework to **evaluate memorization and privacy risks in large language models (LLMs)**.  
It demonstrates how fine-tuned models can memorize sensitive identifiers and explores how **differential privacy (DP)** mitigates leakage while balancing utility.

---

## ‚ú® Features

- **Classification task (DistilBERT)**

  - Fine-tunes DistilBERT on text classification datasets containing synthetic identifiers.
  - Integrates **Opacus** for DP-SGD training.
  - Reports trade-offs between accuracy, privacy budgets (Œµ), and leakage scores.

- **Language modeling task (GPT-2)**

  - Fine-tunes GPT-2 on toy data with _canary strings_ (unique identifiers).
  - Tests for memorization by prompting the model.
  - Demonstrates privacy leakage in generative LLMs.

- **Evaluation metrics**
  - Accuracy / Perplexity for utility.
  - Œµ (privacy budget) for differential privacy guarantees.
  - Canary extraction rate for memorization risk.

---

## üõ†Ô∏è Installation

Clone the repo and install dependencies:

```bash
git clone https://github.com/yourusername/PrivacyLens.git
cd PrivacyLens
pip install -r requirements.txt
```

**Requirements (main):**

- Python 3.9+
- PyTorch
- HuggingFace Transformers
- Opacus

---

## üöÄ Usage

### 1. DistilBERT with Differential Privacy

Train a classifier on synthetic data with/without DP:

```bash
python train_distilbert_dp.py --dp --epsilon 8 --delta 1e-5
```

Arguments:

- `--dp`: enable differential privacy (default: off)
- `--epsilon`: target privacy budget
- `--delta`: privacy delta
- `--epochs`: number of epochs
- `--batch_size`: training batch size

Results are logged as accuracy, Œµ, and leakage scores.

---

### 2. GPT-2 Leakage Demo

Fine-tune GPT-2 on toy data with a _canary identifier_:

```bash
python gpt2_leakage.py
```

If GPT-2 memorized the canary, you may see outputs like:

```
Leakage test outputs:
My secret code is NevinAda123
```

---

## üìä Example Results

| Model      | DP Enabled | Œµ   | Accuracy | Leakage Observed |
| ---------- | ---------- | --- | -------- | ---------------- |
| DistilBERT | No         | ‚àû   | 91%      | High             |
| DistilBERT | Yes        | 8   | 87%      | Low              |
| GPT-2      | No         | ‚àû   | (N/A)    | Canary recovered |

---

## üìÑ Project Status

PrivacyLens is **work-in-progress**. Current scope:

- ‚úÖ DistilBERT with Opacus for DP-SGD
- ‚úÖ GPT-2 canary memorization test
- üîú Extended metrics and benchmarks

---

## üßë‚Äçüíª Author

Nevin Ada √áakmak
University of Toronto, Computer Science (Co-op)
[LinkedIn](https://www.linkedin.com/in/nevin-ada-cakmak/) | [GitHub](https://github.com/nevinadacakmak)
